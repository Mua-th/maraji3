{"cells":[{"cell_type":"markdown","metadata":{"id":"r3Rsz5-jDIaR"},"source":["# 00. Les Bases de PyTorch\n","\n","## Qu'est-ce que PyTorch ?\n","\n","[PyTorch](https://pytorch.org/) est un framework open source d'apprentissage automatique et d'apprentissage profond.\n","\n","## À quoi peut servir PyTorch ?\n","\n","PyTorch vous permet de manipuler et de traiter des données et d'écrire des algorithmes d'apprentissage automatique à l'aide du code Python.\n","\n","## Qui utilise PyTorch ?\n","\n","Un grand nombre des plus grandes entreprises technologiques au monde telles que [**Meta** (Facebook)](https://ai.facebook.com/blog/pytorch-builds-the-future-of-ai-and-machine-learning-at-facebook/ ), **Tesla** et **Microsoft** ainsi que des sociétés de recherche en intelligence artificielle telles que [**OpenAI**](https://openai.com/blog/openai-pytorch/) utilise PyTorch pour conduire de la recherche et intégrer l'apprentissage automatique dans leurs propositions de produits.\n","\n","![pytorch utilisé dans l'industrie et la recherche](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-pytorch-being-used-across-research-and-industry.png )\n","\n","Par exemple, Andrej Karpathy (responsable de l'IA chez Tesla entre 2017 et 2022) a donné plusieurs conférences ([PyTorch DevCon 2019](https://youtu.be/oBklltKXtDE), [Tesla AI Day 2021](https://youtu.be/j0z4FweCy4M ?t=2904)) sur la façon dont Tesla utilise PyTorch pour alimenter ses modèles de vision par ordinateur autonomes.\n","\n","PyTorch est également utilisé dans d'autres secteurs tels que l'agriculture pour [alimenter la vision par ordinateur sur les tracteurs](https://medium.com/pytorch/ai-for-ag-production-machine-learning-for-agriculture-e8cfdb9849a1).\n","\n","## Pourquoi utiliser PyTorch ?\n","\n","Les chercheurs en apprentissage automatique adorent utiliser PyTorch. Et depuis février 2022, PyTorch est le [framework d'apprentissage profond le plus utilisé sur Papers With Code](https://paperswithcode.com/trends), un site Web permettant de suivre les articles de recherche sur l'apprentissage automatique et les référentiels de code qui leur sont associés.\n","\n","PyTorch aide également à prendre en charge de nombreuses choses telles que l'accélération GPU (rendant votre code plus rapide) en coulisse.\n","\n","Vous pouvez donc vous concentrer sur la manipulation des données et l'écriture d'algorithmes et PyTorch veillera à ce qu'il fonctionne rapidement.\n","\n","Et si des entreprises telles que Tesla et Meta (Facebook) l'utilisent pour créer des modèles qu'elles déploient pour alimenter centaines applications, conduire des milliers de voitures et fournir du contenu à des milliards de personnes, cette bibliothéque python est clairement également performante sur le plan du développement pour une mutitude d'usage different.\n","\n","## Ce que nous allons aborder dans ce module\n","\n","Ce cours de **Deep Learning** est découpé en différentes sections (Jupyter Notebook).\n","\n","Chaque Notebook couvrira des idées et des concepts importants dans PyTorch. Ce Notebook traite du conteneur élémentaire des données pour des fins d'apprentissage automatique et de d'apprentissage profond, i.e: ***le tenseur***.\n","\n","Plus précisément, nous allons couvrir dans cette unité :\n","\n","| **Sujet** | **Contenu** |\n","| ----- | ----- |\n","| **Introduction aux tenseurs** | Les tenseurs sont l’élément de base de tout l’apprentissage automatique et de l’apprentissage profond. |\n","| **Création de tenseurs** | Les tenseurs peuvent représenter presque tous les types de données (images, mots, tableaux de nombres). |\n","| **Obtenir des informations à partir des tenseurs** | Si vous pouvez mettre des informations dans un tenseur, vous souhaiterez également les extraire. |\n","| **Manipulation des tenseurs** | Les algorithmes d'apprentissage automatique (comme les réseaux de neurones) impliquent de manipuler les tenseurs de différentes manières, par exemple en ajoutant, en multipliant et en combinant. |\n","| **Gérer les formes tensorielles** | L'un des problèmes les plus courants dans l'apprentissage automatique est la gestion des inadéquations de forme (en essayant de mélanger des tenseurs de mauvaise forme avec d'autres tenseurs). |\n","| **Indexation sur tenseurs** | Si vous avez indexé sur une liste Python ou un tableau NumPy, c'est très similaire aux tenseurs, sauf qu'ils peuvent avoir beaucoup plus de dimensions. |\n","| **Mélanger les tenseurs PyTorch et NumPy** | PyTorch joue avec les tenseurs ([`torch.Tensor`](https://pytorch.org/docs/stable/tensors.html)), NumPy aime les tableaux ([`np.ndarray`](https://numpy.org /doc/stable/reference/generated/numpy.ndarray.html)) parfois, vous souhaiterez les mélanger et les faire correspondre. |\n","| **Reproductibilité** | L'apprentissage automatique est très expérimental et comme il utilise beaucoup de *aléatoire* pour fonctionner, vous souhaiterez parfois que ce *aléatoire* ne soit pas si aléatoire. |\n","| **Exécution de tenseurs sur GPU** | Les GPU (Graphics Processing Units) rendent votre code plus rapide, PyTorch facilite l'exécution de votre code sur des GPU. |\n","\n","## Où pouvez-vous documenter sur  Pytorch ou obtenir de l'aide ?\n","\n","### TODO ajouter la documentation et video d'introduction de Pytorch\n","\n","Il existe également les [forums des développeurs PyTorch](https://discuss.pytorch.org/), un endroit très utile pour tout ce qui concerne PyTorch."]},{"cell_type":"markdown","metadata":{"id":"5v3iRCRUTGeu"},"source":["## Importater PyTorch\n","\n","> **Remarque :** Avant d'exécuter le code de ce notebook, vous devez avoir suivi les [étapes de configuration de PyTorch](https://pytorch.org/get-started/locally/).\n",">\n","> Cependant, **si vous utilisez Google Colab**, tout devrait fonctionner (Google Colab est livré avec PyTorch et d'autres bibliothèques installées).\n","\n","Commençons par importer PyTorch et vérifier la version que nous utilisons."]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"elapsed":5488,"status":"ok","timestamp":1699111277018,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"1VxEOik46Y4i","outputId":"2d9bdf56-e7c9-4691-efca-0075dcd7fa82"},"outputs":[{"data":{"text/plain":["'2.3.0+cpu'"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["import torch\n","torch.__version__"]},{"cell_type":"markdown","metadata":{"id":"i-33BKR16iWc"},"source":["## Introduction aux tenseurs\n","\n","Maintenant que PyTorch est importé, il est temps d'en apprendre davantage sur les tenseurs.\n","\n","Les tenseurs sont l’élément fondamental de l’apprentissage automatique.\n","\n","Leur travail consiste à représenter les données de manière numérique.\n","\n","Par exemple, vous pouvez représenter une image sous forme de tenseur avec la forme « [3, 224, 224] », ce qui signifierait « [colour_channels, height, width] », car l'image a « 3 » canaux de couleur (rouge, vert, bleu), une hauteur de « 224 » pixels et une largeur de « 224 » pixels.\n","\n","![exemple de passage d'une image d'entrée à une représentation tensorielle de l'image, l'image est décomposée en 3 canaux de couleur ainsi que des nombres pour représenter la hauteur et la largeur](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-tensor-shape-example-of-image.png)\n","\n","Dans le langage tensoriel (le langage utilisé pour décrire les tenseurs), le tenseur aurait trois dimensions, une pour « colour_channels », « height » et « width ».\n","\n","Mais nous prenons de l'avance. Apprenons d'abord quelques bases sur les tenseurs en les codant en pratique."]},{"cell_type":"markdown","metadata":{"id":"gFF0N2TU7S7Q"},"source":["### Créer des tenseurs\n","\n","Il existe toute une page de documentation dédiée à la classe [`torch.Tensor`](https://pytorch.org/docs/stable/tensors.html) sur la documentation officiel de Pytorch.\n","\n","Votre premier devoir consiste à [lire la documentation sur `torch.Tensor`](https://pytorch.org/docs/stable/tensors.html) pendant 10 minutes. Mais vous pourrez y revenir plus tard.\n","\n","La première chose que nous allons créer est un **scalaire**.\n","\n","Un scalaire est un nombre unique et, en termes tensoriels, c'est un tenseur de dimension nulle.\n","\n","> **Remarque :** C'est une tendance pour ce cours. Nous nous concentrerons sur l'écriture de code spécifique. Mais souvent, je propose des exercices qui impliquent de lire et de se familiariser avec la documentation PyTorch. Car après tout, une fois ce cours terminé, vous aurez sans doute envie d’en savoir plus. Et la documentation est un endroit où vous vous retrouverez assez souvent."]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1699111277018,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"YUDgG2zk7Us5","outputId":"91b19655-e3cd-418c-9e98-46465cc7b2ce"},"outputs":[{"data":{"text/plain":["tensor(7)"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["# Scalar\n","scalar = torch.tensor(7)\n","scalar"]},{"cell_type":"markdown","metadata":{"id":"JqSuhW7rTGey"},"source":["Voyez comment ce qui précède a imprimé `tensor(7)` ?\n","\n","Cela signifie que bien que « scalaire » soit un nombre unique, il est de type « torch.Tensor ».\n","\n","Nous pouvons vérifier les dimensions d'un tenseur en utilisant l'attribut `ndim`."]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1699111277018,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"lV98Yz868bav","outputId":"58d055ca-07cf-4574-e2ea-6b5258ee6a76"},"outputs":[{"data":{"text/plain":["0"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["scalar.ndim"]},{"cell_type":"markdown","metadata":{"id":"ZO2YW_QGTGez"},"source":["Et si nous voulions récupérer le nombre du tenseur ?\n","\n","Comme dans, le transformer de `torch.Tensor` en un entier Python ?\n","\n","Pour ce faire, nous pouvons utiliser la méthode `item()`."]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1699111277018,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"-k4cyKumPfbE","outputId":"e18f3fde-d6f1-480f-c305-97bb32a330bc"},"outputs":[{"data":{"text/plain":["7"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["scalar.item()"]},{"cell_type":"markdown","metadata":{"id":"qYs7ulrATGe0"},"source":["D'accord, voyons maintenant un **vecteur**.\n","\n","Un vecteur est un tenseur à dimension unique mais peut contenir plusieurs nombres.\n","\n","À titre d'exemple, vous pourriez avoir un vecteur `[3, 2]` pour décrire `[chambres, salles de bains]` dans votre maison. Ou vous pourriez avoir `[3, 2, 2]` pour décrire `[chambres, salles de bains, salon]` dans votre maison.\n","\n","La tendance importante ici est qu'un vecteur est flexible dans ce qu'il peut représenter (idem pour les tenseurs)."]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1699111277018,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"-IZF6ASs8QH9","outputId":"ad3a7852-8553-4506-e4ec-53b393939ff4"},"outputs":[{"data":{"text/plain":["tensor([7, 7])"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["vector = torch.tensor([7, 7])\n","vector"]},{"cell_type":"markdown","metadata":{"id":"mXxRUUW2TGe1"},"source":["Qu'est ce qu'on va trouver on terme de dimension d'un vecteur ?"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1699111277018,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"03hm3VVv8kr4","outputId":"ec381cb7-f085-4903-bdfa-3944dff8a069"},"outputs":[{"data":{"text/plain":["1"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["vector.ndim"]},{"cell_type":"markdown","metadata":{"id":"W0VYvSGbTGe1"},"source":["Vous pouvez connaître le nombre de dimensions d'un tenseur dans PyTorch par le nombre de crochets à l'extérieur (`[`) et vous n'avez besoin de compter qu'un seul côté.\n","\n","Combien de crochets `vector` a-t-il ?\n","\n","Un autre concept important pour les tenseurs est leur attribut `shape`. La forme vous indique comment les éléments à l'intérieur sont disposés.\n","\n","Voyons la forme de `vector`:"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1699111277019,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"6zREV1bDTGe2","outputId":"76ae7085-5bfc-48f7-db01-8b01d6d90cef"},"outputs":[{"data":{"text/plain":["torch.Size([2])"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["vector.shape"]},{"cell_type":"markdown","metadata":{"id":"9aWKppNyTGe2"},"source":["Ce qui précède renvoie `torch.Size([2])`, ce qui signifie que notre vecteur a la forme de `[2]`. Cela est dû aux deux éléments que nous avons placés entre crochets (`[7, 7]`).\n","\n","Voyons maintenant pour une **matrice**."]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1699111277019,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"D5iNwCYL8QO9","outputId":"c2edd153-4d1d-4809-cc7e-8fd80638d12d"},"outputs":[{"data":{"text/plain":["tensor([[ 7,  8],\n","        [ 9, 10]])"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["MATRIX = torch.tensor([[7, 8],\n","                       [9, 10]])\n","MATRIX"]},{"cell_type":"markdown","metadata":{"id":"a3U1bCdjTGe3"},"source":["Les matrices sont une generalisation des vecteur d'une à deux dimension.\n","\n"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1699111277019,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"8LREUbeb8r8j","outputId":"5e06847e-537e-4dca-933e-8a1786850865"},"outputs":[{"data":{"text/plain":["2"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["MATRIX.ndim"]},{"cell_type":"markdown","metadata":{"id":"LhXXgq-dTGe3"},"source":["`MATRIX` a deux dimensions (Priere de compter le nombre de crochets à l'extérieur d'un côté pour s'assurer).\n","\n","> Quelle « forme » pensez-vous qu'il aura ?"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":577,"status":"ok","timestamp":1699111277592,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"_TL26I31TGe3","outputId":"23bc78ae-3e3d-4e14-a331-58936554d05e"},"outputs":[{"data":{"text/plain":["torch.Size([2, 2])"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["MATRIX.shape"]},{"cell_type":"markdown","metadata":{"id":"dvLpUvrKTGe4"},"source":["Nous obtenons le résultat `torch.Size([2, 2])` car `MATRIX` est composé de deux éléments en hauteur et deux éléments en largeur.\n","\n","Et si on créait un **tenseur** ?"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":36,"status":"ok","timestamp":1699111277592,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"wEMDQr188QWW","outputId":"2c64de0d-4cbf-48aa-a9a1-8b88bd5db616"},"outputs":[{"data":{"text/plain":["tensor([[[1, 2, 3],\n","         [3, 6, 9],\n","         [2, 4, 5]]])"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["# Tensor\n","TENSOR = torch.tensor([[[1, 2, 3],\n","                        [3, 6, 9],\n","                        [2, 4, 5]]])\n","TENSOR"]},{"cell_type":"markdown","metadata":{"id":"UmJKkXD7TGe4"},"source":["Je tiens à souligner que les tenseurs peuvent représenter presque tout type de donnée.\n","\n","Celui que nous venons de créer pourrait être les chiffres de ventes d'un magasin de steak et de cotelette de boeuf.\n","\n","![un simple tenseur dans des feuilles Google affichant le jour de la semaine, les ventes de steaks et les ventes de beurre d'amande](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00_simple_tensor.png)\n","\n","À votre avis, combien de dimensions a-t-il ? (indice : utilisez l'astuce de comptage des crochets)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34,"status":"ok","timestamp":1699111277592,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"8dhuEsjS8QcT","outputId":"2d6caccc-e7f6-49fa-951f-0ed1470fe06b"},"outputs":[{"data":{"text/plain":["3"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["TENSOR.ndim"]},{"cell_type":"markdown","metadata":{"id":"ln9dys5VTGe4"},"source":["la forme de `TENSOR` est"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32,"status":"ok","timestamp":1699111277592,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"hdVv4iNRTGe5","outputId":"a6f7db92-7971-41e3-b803-682e75e6b316"},"outputs":[{"data":{"text/plain":["torch.Size([1, 3, 3])"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["TENSOR.shape"]},{"cell_type":"markdown","metadata":{"id":"zxk8GU7oTGe5"},"source":["Très bien, il affiche `torch.Size([1, 3, 3])`.\n","\n","Les dimensions vont de l’extérieur vers l’intérieur.\n","\n","Cela signifie qu'il y a 1 dimension de 3 sur 3.\n","\n","![exemple de différentes dimensions de tenseur](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-pytorch-différent-tensor-dimensions.png)\n","\n","> **Remarque :** Vous m'avez peut-être remarqué en utilisant des lettres minuscules pour « scalaire » et « vecteur » et des lettres majuscules pour « MATRIX » et « TENSOR ». C'était exprès. Dans la pratique, vous verrez souvent des scalaires et des vecteurs désignés par des lettres minuscules telles que « y » ou « a ». Et les matrices et les tenseurs désignés par des lettres majuscules telles que « *X* » ou « *W* ».\n","\n","> Vous remarquerez peut-être également les noms de matrice et de tenseur utilisés de manière interchangeable. C'est courant. Puisque dans PyTorch, vous avez souvent affaire à des « torch.Tensor » (d'où le nom du tenseur), cependant, la forme et les dimensions de ce qu'il y a à l'intérieur dicteront ce qu'il est réellement.\n","\n","Résumons.\n","\n","| Nom | Qu'est-ce que c'est? | Nombre de dimensions | Inférieur ou supérieur (généralement/exemple) |\n","| ----- | ----- | ----- | ----- |\n","| **scalaire** | un seul numéro | 0 | (`a`) |\n","| **vecteur** | un nombre avec une direction (par exemple la vitesse du vent avec une direction) mais peut aussi avoir de nombreux autres nombres | 1 |  (`y`) |\n","| **matrice** | un tableau de nombres à 2 dimensions | 2 |  (`Q`) |\n","| **tenseur** | un tableau de nombres à n dimensions | int(*) | (`X`) |\n","\n","![Tenseur de matrice vectorielle scalaire et à quoi ils ressemblent](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-scalar-vector-matrix-tensor.png)"]},{"cell_type":"markdown","metadata":{"id":"dms7G4nkTGe5"},"source":["### Tenseurs aléatoires\n","\n","Nous avons établi que les tenseurs représentent une certaine forme de données.\n","\n","Et les modèles d’apprentissage automatique tels que les réseaux de neurones manipulent, recherchent, et identifient des structures (***Pattern***)  au sein des tenseurs.\n","\n","Mais lors de la création de modèles d'apprentissage automatique avec PyTorch, il est rare que vous créiez des tenseurs à la main (comme ce que nous faisons).\n","\n","Au lieu de cela, un modèle d’apprentissage automatique commence souvent avec de grands tenseurs de nombres aléatoires et ajuste ces nombres aléatoires au fur et à mesure qu’il traite les données pour mieux les représenter.\n","\n","De manière systématique, il s'agit de :\n","\n","`Commencez avec des nombres aléatoires -> regardez les données -> mettez à jour les nombres aléatoires -> regardez les données -> mettez à jour les nombres aléatoires...`\n","\n","En tant que data scientist, vous pouvez définir comment le modèle d'apprentissage automatique démarre (initialisation), examine les données (représentation) et met à jour (optimisation) ses nombres aléatoires.\n","\n","Pour l'instant, voyons comment créer un tenseur de nombres aléatoires.\n","\n","Nous pouvons faire usage de [`torch.rand()`](https://pytorch.org/docs/stable/generated/torch.rand.html) et en passant le paramètre `size`."]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31,"status":"ok","timestamp":1699111277592,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"EOJEtDx--GnK","outputId":"f4267a25-6ef1-4a53-9e4b-048bc1227fd0"},"outputs":[{"data":{"text/plain":["(tensor([[0.0984, 0.0094, 0.9214, 0.1687],\n","         [0.1996, 0.7544, 0.8329, 0.3541],\n","         [0.5482, 0.7073, 0.4868, 0.1314]]),\n"," torch.float32)"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["random_tensor = torch.rand(size=(3, 4))\n","random_tensor, random_tensor.dtype"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"data":{"text/plain":["2"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["random_tensor.ndim"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([[0.9927, 0.4917, 0.4362, 0.7714],\n","        [0.0612, 0.8523, 0.9427, 0.7165],\n","        [0.0985, 0.8770, 0.2601, 0.8814]])"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["randtens = torch.rand(size=(3,4))\n","randtens"]},{"cell_type":"markdown","metadata":{"id":"-wB1c_cXTGe5"},"source":["La flexibilité de `torch.rand()` est que nous pouvons ajuster la `taille` pour qu'elle soit ce que nous voulons.\n","\n","Par exemple, disons que vous vouliez un tenseur aléatoire dans la forme d'image commune de `[224, 224, 3]` (`[hauteur, largeur, color_channels`])."]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29,"status":"ok","timestamp":1699111277592,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"xMF_NUp3Ym__","outputId":"cf12de02-427e-49da-bbdd-3d6f297e7e65"},"outputs":[{"data":{"text/plain":["(torch.Size([224, 224, 3]), 3)"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["random_image_size_tensor = torch.rand(size=(224, 224, 3))\n","random_image_size_tensor.shape, random_image_size_tensor.ndim"]},{"cell_type":"markdown","metadata":{"id":"0MQNTY0eTGe6"},"source":["### Des zéros et des uns\n","\n","Parfois, vous souhaiterez simplement remplir les tenseurs avec des zéros ou des uns.\n","\n","Cela arrive souvent avec le masquage (comme masquer certaines valeurs d'un tenseur avec des zéros pour empêcher un modèle de deep learning de prendre en consideration ces valeurs dans la procedure d'entrainement).\n","\n","Créons un tenseur plein de zéros avec [`torch.zeros()`](https://pytorch.org/docs/stable/generated/torch.zeros.html)\n","\n","Encore une fois, le paramètre « size » entre en jeu."]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27,"status":"ok","timestamp":1699111277592,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"oCzhd0hl9Vp6","outputId":"408fa37e-f481-4b2b-d21b-c147c1882e4a"},"outputs":[{"data":{"text/plain":["(tensor([[0., 0., 0., 0.],\n","         [0., 0., 0., 0.],\n","         [0., 0., 0., 0.]]),\n"," torch.float32)"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["zeros = torch.zeros(size=(3, 4))\n","zeros, zeros.dtype"]},{"cell_type":"markdown","metadata":{"id":"WDQBZJRUZWTN"},"source":["Nous pouvons faire la même chose pour créer un tenseur rempli de 1 en utilisant [`torch.ones()` ](https://pytorch.org/docs/stable/generated/torch.ones.html)\n","\n","---"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26,"status":"ok","timestamp":1699111277592,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"HRe6sSXiTGe6","outputId":"9c3e3b42-c787-4e0f-fa5b-2ae7f5ae2d3c"},"outputs":[{"data":{"text/plain":["(tensor([[1., 1., 1., 1.],\n","         [1., 1., 1., 1.],\n","         [1., 1., 1., 1.]]),\n"," torch.float32)"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["ones = torch.ones(size=(3, 4))\n","ones, ones.dtype"]},{"cell_type":"markdown","metadata":{"id":"hib1NYrSarL2"},"source":["### Création d'un range de tenseurs :\n","\n","Parfois, vous souhaiterez peut-être une plage de nombres (`range`), telle que 1 à 10 ou 0 à 100.\n","\n","Vous pouvez utiliser `torch.arange(start, end, step)` pour le faire.\n","\n","Où:\n","* `start` = début du range (par exemple 0)\n","* `end` = fin du range (par exemple 10)\n","* `step` = le pas entre chaque valeur (par exemple 1)\n","\n","> **Remarque :** En Python, vous pouvez utiliser le python native `range()`. Cependant, dans PyTorch, `torch.range()` est obsolète et peut afficher une erreur à l'avenir."]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25,"status":"ok","timestamp":1699111277592,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"1IqUs81d9W4W","outputId":"9484ec7d-7e7e-4d80-837c-79705852e3b3"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_19976\\1693756618.py:1: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n","  zero_to_ten_deprecated = torch.range(0, 10)\n"]},{"data":{"text/plain":["tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["zero_to_ten_deprecated = torch.range(0, 10)\n","\n","#utilisation recomendée\n","zero_to_ten = torch.arange(start=0, end=10, step=1)\n","zero_to_ten"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([[[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n","         [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]]])"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["mytensor = torch.tensor([[\n","    torch.arange(start=0, end=10, step= 1).tolist(),\n","    torch.arange(start=10, end=20, step= 1).tolist()]\n","])\n","mytensor"]},{"cell_type":"markdown","metadata":{"id":"i-bXf0Ugbh-D"},"source":["Parfois, vous souhaiterez peut-être qu'un tenseur d'un certain type ait la même forme qu'un autre tenseur.\n","\n","Par exemple, un tenseur composé uniquement de zéros avec la même forme qu'un tenseur précédent.\n","\n","Pour ce faire, vous pouvez utiliser [`torch.zeros_like(input)`](https://pytorch.org/docs/stable/generated/torch.zeros_like.html) ou [`torch.ones_like(input)`](https ://pytorch.org/docs/1.9.1/generated/torch.ones_like.html) qui renvoient respectivement un tenseur rempli de zéros ou de uns de la même forme que « l'entrée »."]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1699111277593,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"ZvXwUut5BhHq","outputId":"bfdbedc1-1cbf-4399-8ad0-3fddf8d824a1"},"outputs":[{"data":{"text/plain":["tensor([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]])"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["ten_zeros = torch.zeros_like(input=mytensor)\n","ten_zeros"]},{"cell_type":"markdown","metadata":{"id":"w1IGLRQlYShc"},"source":["### Types de données Tenseurs\n","\n","Il existe de nombreux [types de données tenseurs disponibles dans PyTorch](https://pytorch.org/docs/stable/tensors.html#data-types).\n","\n","Certains sont spécifiques au CPU et d’autres sont meilleurs pour le GPU.\n","\n","Savoir lequel est lequel peut prendre un certain temps.\n","\n","Généralement, si vous voyez « torch.cuda » n'importe où, le tenseur est utilisé pour le GPU (puisque les GPU Nvidia utilisent une boîte à outils informatique appelée CUDA).\n","\n","Le type le plus courant (et généralement celui par défaut) est « torch.float32 » ou « torch.float ».\n","\n","C'est ce qu'on appelle une « virgule flottante 32 bits ».\n","\n","Mais il existe également des virgules flottantes 16 bits (`torch.float16` ou `torch.half`) et des virgules flottantes 64 bits (`torch.float64` ou `torch.double`).\n","\n","Et pour rendre les choses encore plus confuses, il existe également des entiers de 8 bits, 16 bits, 32 bits et 64 bits.\n","\n","Et plus encore !\n","\n","> **Remarque :** Un entier est un nombre rond et plat comme « 7 » alors qu'un flottant a un nombre décimal « 7.0 ».\n","\n","La raison de tout cela est liée à la **précision informatique**.\n","\n","La précision est la quantité de détails utilisée pour décrire un nombre.\n","\n","Plus la valeur de précision (8, 16, 32) est élevée, plus il y a de détails et donc de données utilisées pour exprimer un nombre.\n","\n","Cela est important dans l'apprentissage profond et le calcul numérique, car vous effectuez tellement d'opérations que plus vous devez calculer en détail, plus vous augementer la complexité des calculs.\n","\n","Ainsi, les types de données de précision inférieure sont généralement plus rapides à calculer, mais sacrifient certaines performances sur les métriques d'évaluation telles que la précision (plus rapides à calculer mais moins précises).\n","\n","> **Ressources :**\n","   * Consultez la [documentation PyTorch pour une liste de tous les types de données tenseurs disponibles](https://pytorch.org/docs/stable/tensors.html#data-types).\n","   * Lisez la [page Wikipédia pour un aperçu de ce qu'est la précision en informatique](https://en.wikipedia.org/wiki/Precision_(computer_science)).\n","\n","Voyons comment créer des tenseurs avec des types de données spécifiques. Nous pouvons le faire en utilisant le paramètre `dtype`."]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1699111277593,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"q3MoGnpw9XaF","outputId":"525fd80b-84c5-45db-cc76-8f89b7bea517"},"outputs":[{"data":{"text/plain":["(torch.Size([3]), torch.float32, device(type='cpu'))"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["float_32_tensor = torch.tensor([3.0, 6.0, 9.0],\n","                               dtype=None,\n","                               device=None,\n","                               requires_grad=False)\n","float_32_tensor.shape, float_32_tensor.dtype, float_32_tensor.device"]},{"cell_type":"markdown","metadata":{"id":"MhP8kzDfe_ty"},"source":["Outre que les problèmes de forme (les formes des tenseurs ne correspondent pas), deux des autres problèmes les plus courants que vous rencontrerez dans PyTorch sont les problèmes de type de données et de périphérique.\n","\n","Par exemple, l'un des tenseurs est « torch.float32 » et l'autre est « torch.float16 » (PyTorch necessite souvent que les tenseurs aient le même format).\n","\n","Ou bien l'un de vos tenseurs est sur le CPU et l'autre sur le GPU (PyTorch requiert que les calculs entre tenseurs soient sur le même appareil).\n","\n","Pour l'instant, créons un tenseur avec `dtype=torch.float16`."]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1699111277593,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"PKSuajld_09s","outputId":"f67bf728-711b-4c40-a87e-0d92fbb74c7e"},"outputs":[{"data":{"text/plain":["torch.float16"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["float_16_tensor = torch.tensor([3.0, 6.0, 9.0],\n","                               dtype=torch.float16)\n","\n","float_16_tensor.dtype"]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1699111277593,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"bzi1gnhiayMB","outputId":"eba53868-7dda-48eb-de5b-a23d93ef32bc"},"outputs":[{"data":{"text/plain":["tensor([ 6., 12., 18.])"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["float_32_tensor+float_16_tensor # operation permise due au conversion implicite mais fortement déconseiller"]},{"cell_type":"markdown","metadata":{"id":"gUjkB2AX7Upz"},"source":["## Obtenir des informations à partir des tenseurs\n","\n","Une fois que vous avez créé des tenseurs (ou que quelqu'un d'autre ou un module PyTorch les a créés pour vous), vous souhaiterez peut-être en obtenir des informations.\n","\n","Nous les avons déjà vus, mais trois des attributs les plus courants que vous voudrez découvrir sur les tenseurs sont :\n","* `shape` - quelle est la forme du tenseur ? (certaines opérations nécessitent des règles de forme spécifiques)\n","* `dtype` - dans quel type de données les éléments du tenseur sont-ils stockés ?\n","* `device` - sur quel appareil le tenseur est-il stocké ? (généralement GPU ou CPU)\n","\n","Créons un tenseur aléatoire et découvrons des détails à ce sujet."]},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1699111277593,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"hd_X4D0j7Umq","outputId":"c37f3ec3-7e96-467e-a578-24d43bcfabda"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[0.2421, 0.0883, 0.1793, 0.3778],\n","        [0.5022, 0.6661, 0.7132, 0.3792],\n","        [0.6801, 0.9651, 0.3184, 0.6965]])\n","shape : torch.Size([3, 4])\n","dtype : torch.float32\n","device: cpu\n"]}],"source":["some_tensor = torch.rand(3, 4)\n","\n","print(some_tensor)\n","print(f\"shape : {some_tensor.shape}\")\n","print(f\"dtype : {some_tensor.dtype}\")\n","print(f\"device: {some_tensor.device}\")"]},{"cell_type":"markdown","metadata":{"id":"45K-E5uPg6cj"},"source":["> **Remarque :** Lorsque vous rencontrez des problèmes dans PyTorch, il s'agit très souvent d'un problème lié à l'un des trois attributs ci-dessus. Alors, lorsque les messages d'erreur apparaissent, Pensez à faire un débuggage avec l'affichage précédent :\n","   * \"*de quelle forme sont mes tenseurs ? de quel type de données sont-ils et où sont-ils stockés ? quelle forme, quel type de données, et où ?*\""]},{"cell_type":"markdown","metadata":{"id":"BdiWvoAi7UjL"},"source":["## Manipulation des tenseurs (opérations tensorielles)\n","\n","Dans le deep learning, les données (images, texte, vidéo, audio, structures protéiques, etc.) sont représentées sous forme de tenseurs.\n","\n","Un modèle apprend à partir de ces tenseurs et en effectuant une série d'opérations (pouvant atteindre plus de +1M million) sur les tenseurs pour créer une représentation des modèles dans les données d'entrée.\n","\n","Ces opérations sont souvent une combinaisons :\n","* Ajout\n","* Soustraction\n","* Multiplication/ Division (élément par élément)\n","* Multiplication matricielle\n","\n","\n","Bien sûr, il y en a quelques autres ici et là, mais ce sont les éléments de base des fonctions constituant les réseaux de neurones.\n","\n","En empilant ces éléments de base de la bonne manière, vous pouvez créer les réseaux de neurones les plus sophistiqués."]},{"cell_type":"markdown","metadata":{"id":"Sk_6Dd7L7Uce"},"source":["### Opérations de base\n","\n","Commençons par quelques-unes des opérations fondamentales, addition (`+`), soustraction (`-`), mutliplication (`*`).\n","\n","Ils fonctionnent exactement comme vous le pensez."]},{"cell_type":"code","execution_count":38,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1699111277593,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"X71WpQoPD7a4","outputId":"fe3d920d-84f1-41cf-a229-568b306b16e4"},"outputs":[{"data":{"text/plain":["(tensor([11, 12, 13]), torch.Size([3]))"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["tensor = torch.tensor([1, 2, 3])\n","tensor + 10 , tensor.shape"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1699111277593,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"Sp4TlTWWEFeO","outputId":"2c5f2c9c-e9d2-499c-e0f8-d9c66bdbd8e7"},"outputs":[{"data":{"text/plain":["tensor([10, 20, 30])"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["tensor * 10"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1699111277593,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"XuB1UjCIEJIA","outputId":"839d573d-034c-4365-caec-115fd1946233"},"outputs":[{"data":{"text/plain":["tensor([1, 2, 3])"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["tensor"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1699111277593,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"U4iWKoLsENry","outputId":"5cffb2fd-2802-43d8-992f-10ec1e8f00c2"},"outputs":[{"data":{"text/plain":["tensor([-9, -8, -7])"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["tensor = tensor - 10\n","tensor"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1699111277593,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"tFgZY-PaFNXa","outputId":"877e9399-c0cd-4af2-eaea-0d2462387249"},"outputs":[{"data":{"text/plain":["tensor([1, 2, 3])"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["tensor = tensor + 10\n","tensor"]},{"cell_type":"markdown","metadata":{"id":"CYXDoIOzk-6I"},"source":["PyTorch a également un tas de fonctions intégrées comme [`torch.mul()`](https://pytorch.org/docs/stable/generated/torch.mul.html#torch.mul) (abréviation de multiplication) et [`torch.add()`](https://pytorch.org/docs/stable/generated/torch.add.html) pour effectuer les opérations de base."]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1699111277593,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"uVysdk3kFWbY","outputId":"748c8251-3d6b-4232-b02b-17fdd47536a2"},"outputs":[{"data":{"text/plain":["tensor([10, 20, 30])"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["torch.multiply(tensor, 10)"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1699111277593,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"IxuPJIpNFbqO","outputId":"770a3918-7523-4441-8aa8-e480443ba649"},"outputs":[{"data":{"text/plain":["tensor([1, 2, 3])"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["tensor"]},{"cell_type":"markdown","metadata":{"id":"70UNL33AlVQq"},"source":["However, it's more common to use the operator symbols like `*` instead of `torch.mul()`"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1699111277593,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"S5v3RkR0F2Jq","outputId":"83121cb6-ee1e-453d-9fcd-d7151107c6c6"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([1, 2, 3]) * tensor([1, 2, 3])  est égale à: tensor([1, 4, 9])\n"]}],"source":["print(tensor, \"*\", tensor,\" est égale à:\", tensor * tensor)"]},{"cell_type":"markdown","metadata":{"id":"TT5fVuyu7q5z"},"source":["### La multiplication matricielle\n","\n","L'une des opérations les plus courantes dans les algorithmes d'apprentissage automatique et d'apprentissage profond (comme les réseaux de neurones) est la [multiplication matricielle](https://www.mathsisfun.com/algebra/matrix-multiplying.html).\n","\n","PyTorch implémente la fonctionnalité de multiplication matricielle dans la méthode [`torch.matmul()`](https://pytorch.org/docs/stable/generated/torch.matmul.html).\n","\n","Les deux principales règles de multiplication matricielle à retenir sont :\n","\n","1. Les **dimensions intérieures** doivent correspondre :\n","   * `(3, 2) @ (3, 2)` ne fonctionnera pas\n","   * `(2, 3) @ (3, 2)` fonctionnera\n","   * `(3, 2) @ (2, 3)` fonctionnera\n","2. La matrice résultante a la forme des **dimensions extérieures** :\n","  * `(2, 3) @ (3, 2)` -> `(2, 2)`\n","  * `(3, 2) @ (2, 3)` -> `(3, 3)`\n","\n","> **Remarque :** \"`@`\" en Python est le symbole de la multiplication matricielle.\n","\n","> **Ressource :** Vous pouvez voir toutes les règles de multiplication matricielle en utilisant `torch.matmul()` [dans la documentation PyTorch](https://pytorch.org/docs/stable/generated/torch.matmul. html).\n","\n","Créons un tenseur et effectuons dessus une multiplication par éléments et une multiplication matricielle."]},{"cell_type":"code","execution_count":39,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1699111277593,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"ZE7loucmDlEM","outputId":"9af4a29f-c1af-41a1-caf6-92c06979253b"},"outputs":[{"data":{"text/plain":["torch.Size([3])"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["tensor = torch.tensor([1, 2, 3])\n","tensor.shape"]},{"cell_type":"markdown","metadata":{"id":"VUAZ3_b0vOKv"},"source":["La différence entre la multiplication par éléments et la multiplication matricielle réside dans l'ajout de valeurs.\n","\n","Pour notre variable `tensor` avec les valeurs `[1, 2, 3]` :\n","\n","| Opération | Calcul | Codes |\n","| ----- | ----- | ----- |\n","| **Multiplication par éléments** | `[1*1, 2*2, 3*3]` = `[1, 4, 9]` | `tenseur * tenseur` |\n","| **Multiplication matricielle** | `[1*1 + 2*2 + 3*3]` = `[14]` | `tensor.matmul(tenseur)` |"]},{"cell_type":"code","execution_count":42,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1699111277593,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"i42gkUeHvI_1","outputId":"5f97b760-2556-4dcf-a362-c95809e39a3d"},"outputs":[{"data":{"text/plain":["tensor([1, 4, 9])"]},"execution_count":42,"metadata":{},"output_type":"execute_result"}],"source":["tensor * tensor"]},{"cell_type":"code","execution_count":43,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1699111277593,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"PvCBiiTTDk8y","outputId":"5216d3e9-8444-4255-f98a-d324fa26f69a"},"outputs":[{"data":{"text/plain":["tensor(14)"]},"execution_count":43,"metadata":{},"output_type":"execute_result"}],"source":["torch.matmul(tensor, tensor)"]},{"cell_type":"code","execution_count":44,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1699111277593,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"m4E_pROBDk2r","outputId":"a5f01c52-be6e-4df3-8302-ef9942437bc7"},"outputs":[{"data":{"text/plain":["tensor(14)"]},"execution_count":44,"metadata":{},"output_type":"execute_result"}],"source":["tensor @ tensor"]},{"cell_type":"markdown","metadata":{"id":"obbginUMv43A"},"source":["Vous pouvez effectuer une multiplication matricielle à la main, mais ce n'est pas recommandé.\n","\n","La méthode intégrée `torch.matmul()` est plus rapide."]},{"cell_type":"code","execution_count":45,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1699111277986,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"6qMSaLOoJscL","outputId":"1db18fe2-430f-4af1-ed8d-beeddb92b161"},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: total: 0 ns\n","Wall time: 7 ms\n"]},{"data":{"text/plain":["tensor(14)"]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["%%time\n","value = 0\n","for i in range(len(tensor)):\n","  value += tensor[i] * tensor[i]\n","value"]},{"cell_type":"code","execution_count":46,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1699111277987,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"vVWiKB0KwH74","outputId":"b0c01ac7-6d62-4941-dc8d-234c5145db65"},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: total: 0 ns\n","Wall time: 0 ns\n"]},{"data":{"text/plain":["tensor(14)"]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":["%%time\n","torch.matmul(tensor, tensor)"]},{"cell_type":"markdown","metadata":{"id":"aJ4DDmo1TGe-"},"source":["## L'une des erreurs les plus courantes en deep learning (erreurs de forme)\n","\n","Étant donné qu'une grande partie de l'apprentissage profond consiste à se multiplier et que l'exécution d'opérations sur des matrices et que les matrices ont une règle stricte quant aux formes et aux tailles qui peuvent être combinées, l'une des erreurs les plus courantes que vous rencontrerez dans l'apprentissage profond est l'inadéquation des formes."]},{"cell_type":"code","execution_count":48,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":217},"executionInfo":{"elapsed":4,"status":"error","timestamp":1699111277987,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"rN5RcoD4Jo6y","outputId":"be76b929-aab5-47c4-82b7-73152842680c"},"outputs":[{"ename":"RuntimeError","evalue":"mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[1;32mIn[48], line 9\u001b[0m\n\u001b[0;32m      1\u001b[0m tensor_A \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m],\n\u001b[0;32m      2\u001b[0m                          [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m],\n\u001b[0;32m      3\u001b[0m                          [\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m6\u001b[39m]], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m      5\u001b[0m tensor_B \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m10\u001b[39m],\n\u001b[0;32m      6\u001b[0m                          [\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m11\u001b[39m],\n\u001b[0;32m      7\u001b[0m                          [\u001b[38;5;241m9\u001b[39m, \u001b[38;5;241m12\u001b[39m]], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m----> 9\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_A\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_B\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#error\u001b[39;00m\n","\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"]}],"source":["tensor_A = torch.tensor([[1, 2],\n","                         [3, 4],\n","                         [5, 6]], dtype=torch.float32)\n","\n","tensor_B = torch.tensor([[7, 10],\n","                         [8, 11],\n","                         [9, 12]], dtype=torch.float32)\n","\n","torch.matmul(tensor_A, tensor_B) #error"]},{"cell_type":"markdown","metadata":{"id":"HNA6MZEFxWVt"},"source":["Nous pouvons faire fonctionner la multiplication matricielle entre `tensor_A` et `tensor_B` en faisant correspondre leurs dimensions intérieures.\n","\n","L'une des façons de procéder consiste à utiliser une **transposition** (changer les dimensions d'un tenseur donné).\n","\n","Vous pouvez effectuer des transpositions dans PyTorch en utilisant soit :\n","* `torch.transpose(input, dim0, dim1)` - où `input` est le tenseur souhaité à transposer et `dim0` et `dim1` sont les dimensions à permuter.\n","* `tensor.T` - où `tensor` est le tenseur que vous souhaitez transposer.\n","\n","Essayons ce dernier."]},{"cell_type":"code","execution_count":49,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1699111297690,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"lUqgaANiy1wq","outputId":"e9cf8faa-664e-4a8d-9713-cb0731f238b1"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[1., 2.],\n","        [3., 4.],\n","        [5., 6.]])\n","tensor([[ 7., 10.],\n","        [ 8., 11.],\n","        [ 9., 12.]])\n"]}],"source":["# View tensor_A and tensor_B\n","print(tensor_A)\n","print(tensor_B)"]},{"cell_type":"code","execution_count":50,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1699111298727,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"DveqxO7iy_Fi","outputId":"bcf5e87e-069f-481c-ddac-20e46fba228e"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[1., 2.],\n","        [3., 4.],\n","        [5., 6.]])\n","tensor([[ 7.,  8.,  9.],\n","        [10., 11., 12.]])\n"]}],"source":["# View tensor_A and tensor_B.T\n","print(tensor_A)\n","print(tensor_B.T)"]},{"cell_type":"code","execution_count":51,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1699111299656,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"35rEIu-NKtVE","outputId":"5a8232a2-6ab9-4e49-d16b-ac3a5e88a744"},"outputs":[{"name":"stdout","output_type":"stream","text":["Original shapes: tensor_A = torch.Size([3, 2]), tensor_B = torch.Size([3, 2])\n","\n","New shapes: tensor_A = torch.Size([3, 2]) (same as above), tensor_B.T = torch.Size([2, 3])\n","\n","Multiplying: torch.Size([3, 2]) * torch.Size([2, 3]) <- inner dimensions match\n","\n","Output:\n","\n","tensor([[ 27.,  30.,  33.],\n","        [ 61.,  68.,  75.],\n","        [ 95., 106., 117.]])\n","\n","Output shape: torch.Size([3, 3])\n"]}],"source":["# The operation works when tensor_B is transposed\n","print(f\"Original shapes: tensor_A = {tensor_A.shape}, tensor_B = {tensor_B.shape}\\n\")\n","print(f\"New shapes: tensor_A = {tensor_A.shape} (same as above), tensor_B.T = {tensor_B.T.shape}\\n\")\n","print(f\"Multiplying: {tensor_A.shape} * {tensor_B.T.shape} <- inner dimensions match\\n\")\n","print(\"Output:\\n\")\n","output = torch.matmul(tensor_A, tensor_B.T)\n","print(output)\n","print(f\"\\nOutput shape: {output.shape}\")"]},{"cell_type":"markdown","metadata":{"id":"MfcFEqfLjN24"},"source":["Il existe aussi la méthode [`torch.mm()`](https://pytorch.org/docs/stable/generated/torch.mm.html) qui est un racourcis de `torch.matmul()`."]},{"cell_type":"code","execution_count":43,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1699111304015,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"x3rJvW_TTGe_","outputId":"65ec6a0c-4bf7-4907-d491-0aaedd7feb29"},"outputs":[{"data":{"text/plain":["tensor([[ 27.,  30.,  33.],\n","        [ 61.,  68.,  75.],\n","        [ 95., 106., 117.]])"]},"execution_count":43,"metadata":{},"output_type":"execute_result"}],"source":["torch.mm(tensor_A, tensor_B.T)"]},{"cell_type":"markdown","metadata":{"id":"hA64Z4DmkB31"},"source":["Les réseaux de neurones sont formés par de multiplications matricielles et de produits scalaires.\n","\n","Le module [`torch.nn.Linear()`](https://pytorch.org/docs/1.9.1/generated/torch.nn.Linear.html), également connue sous le nom de couche feed-forward ou couche entièrement connectée, implémente une multiplication matricielle entre une entrée « x » et une matrice de pondération « A ».\n","\n","$$\n","y = x\\cdot{A^T} + b\n","$$\n","\n","Où:\n","* `x` est l'entrée de la couche (le deep learning est une composition successive de couches comme `torch.nn.Linear()` et d'autres les unes suivis d'autres, etc...).\n","* `A` est la matrice de pondération  constituée de poids créée par la couche, cela commence par des nombres aléatoires qui sont ajustés à mesure qu'un réseau neuronal apprend à mieux représenter les modèles dans les données (remarquez le \"`T`\", c'est parce que la matrice de pondération est transposée ).\n","   * **Remarque :** Vous pouvez également souvent voir « X » ou une autre lettre comme « W » utilisée pour présenter la matrice de pondération pour designer les poids := weights.\n","* « b » est le terme de biais utilisé pour compenser légèrement les pondérations et les entrées.\n","* `y` est la sortie (une manipulation de l'entrée dans l'espoir d'y découvrir des modèles).\n","\n","\n","testons cette couche linéaire.\n","\n","Essayez de changer les valeurs de « in_features » et « out_features » ci-dessous et voyez ce qui se passe.\n","\n","Remarquez-vous quelque chose à voir avec les formes ?"]},{"cell_type":"code","execution_count":44,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":263,"status":"ok","timestamp":1699111681087,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"mC_MjKW1LX7T","outputId":"a931cfc7-aa96-4897-8526-cae2fad803fb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Input shape: torch.Size([3, 2])\n","\n","Output:\n","tensor([[2.2368, 1.2292, 0.4714, 0.3864, 0.1309, 0.9838],\n","        [4.4919, 2.1970, 0.4469, 0.5285, 0.3401, 2.4777],\n","        [6.7469, 3.1648, 0.4224, 0.6705, 0.5493, 3.9716]],\n","       grad_fn=<AddmmBackward0>)\n","\n","Output shape: torch.Size([3, 6])\n"]}],"source":["torch.manual_seed(42)\n","linear = torch.nn.Linear(in_features=2, # in_features = matches inner dimension of input\n","                         out_features=6) # out_features = describes outer value\n","x = tensor_A\n","output = linear(x)\n","print(f\"Input shape: {x.shape}\\n\")\n","print(f\"Output:\\n{output}\\n\\nOutput shape: {output.shape}\")"]},{"cell_type":"markdown","metadata":{"id":"zIGrP5j1pN7j"},"source":["> **Question :** Que se passe-t-il si vous modifiez « in_features » de 2 à 3 ci-dessus ? Est-ce une erreur ? Comment pourriez-vous changer la forme de l'entrée (`x`) pour vous adapter à l'erreur ? Indice : travaillons maintenant avec `tensor_B` au lieu de `tensor_A`."]},{"cell_type":"markdown","metadata":{"id":"pjMmrJOOPv5e"},"source":["### Trouver le min, le max, la moyenne, la somme, etc. (agrégation)\n","\n","Maintenant que nous avons vu quelques façons de manipuler les tenseurs, passons en revue quelques façons de les agréger (passer de plus de valeurs à moins de valeurs).\n","\n","Nous allons d’abord créer un tenseur, puis en trouver le maximum, le minimum, la moyenne et la somme."]},{"cell_type":"code","execution_count":45,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":276,"status":"ok","timestamp":1699112118630,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"jrFQbe5fP1Rk","outputId":"2b56d586-e3c5-4f98-ccb8-fa0399b909ec"},"outputs":[{"data":{"text/plain":["tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["x = torch.arange(0, 100, 10)\n","x"]},{"cell_type":"code","execution_count":48,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":263,"status":"ok","timestamp":1699112176425,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"e5wSP9YKP3Lb","outputId":"9a333ee0-fb3e-43ab-8491-5d1b7ad5414a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Minimum: 0\n","Maximum: 90\n","Mean: 45.0\n","Sum: 450\n"]}],"source":["print(f\"Minimum: {x.min()}\")\n","print(f\"Maximum: {x.max()}\")\n","#print(f\"Mean: {x.mean()}\") # error\n","print(f\"Mean: {x.type(torch.float32).mean()}\")\n","print(f\"Sum: {x.sum()}\")"]},{"cell_type":"markdown","metadata":{"id":"JHoKpsg3sKQE"},"source":["> **Remarque :** Certaines méthodes telles que `torch.mean()` peuvent nécessiter\n","les tenseurs doivent être dans `torch.float32` (le plus courant) ou dans un autre type de données spécifique, sinon l'opération échouera.\n","\n","Vous pouvez également faire la même chose que ci-dessus avec les méthodes « torch »."]},{"cell_type":"code","execution_count":49,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":416,"status":"ok","timestamp":1699112228741,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"0Cr23Y9uP3HO","outputId":"8fc27ced-7d82-42c0-e4be-fbd7a22136fa"},"outputs":[{"data":{"text/plain":["(tensor(90), tensor(0), tensor(45.), tensor(450))"]},"execution_count":49,"metadata":{},"output_type":"execute_result"}],"source":["torch.max(x), torch.min(x), torch.mean(x.type(torch.float32)), torch.sum(x)"]},{"cell_type":"markdown","metadata":{"id":"i7ApCaZjDkvp"},"source":["### Positionnement min/max\n","\n","Vous pouvez également trouver l'indice d'un tenseur où existe le maximum ou le minimum avec [`torch.argmax()`](https://pytorch.org/docs/stable/generated/torch.argmax.html) et [`torch .argmin()`](https://pytorch.org/docs/stable/generated/torch.argmin.html) respectivement.\n","\n","Ceci est utile dans le cas où vous souhaitez simplement la position où se trouve la valeur la plus élevée (ou la plus basse) et non la valeur réelle elle-même (comme lors de l'utilisation de la [fonction d'activation softmax pour une classification multi-classe](https://pytorch.org /docs/stable/generated/torch.nn.Softmax.html))."]},{"cell_type":"code","execution_count":51,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1699112666810,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"FzNBl9JSGlHi","outputId":"e132d63f-db9e-413b-cd5c-e13a681f5cb7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Tensor: tensor([10, 20, 30, 40, 50, 60, 70, 80, 90])\n","Index where max value occurs: 8\n","Index where min value occurs: 0\n"]}],"source":["tensor = torch.arange(10, 100, 10)\n","print(f\"Tensor: {tensor}\")\n","\n","print(f\"Index where max value occurs: {tensor.argmax()}\")\n","print(f\"Index where min value occurs: {tensor.argmin()}\")"]},{"cell_type":"markdown","metadata":{"id":"QBu33WihOXBk"},"source":["### Changer le type de données du tenseur\n","\n","Comme mentionné, un problème courant avec les opérations d'apprentissage en profondeur est que vos tenseurs sont dans différents types de données.\n","\n","Si un tenseur est codé sur `torch.float64` et un autre sur `torch.float32`, vous pourriez rencontrer des erreurs.\n","\n","Mais il existe une solution.\n","\n","Vous pouvez modifier les types de données des tenseurs en utilisant [`torch.Tensor.type(dtype=None)`](https://pytorch.org/docs/stable/generated/torch.Tensor.type.html) où le `dtype` Le paramètre est le type de données que vous souhaitez utiliser.\n","\n","Nous allons d'abord créer un tenseur et vérifier son type de données (la valeur par défaut est `torch.float32`)."]},{"cell_type":"code","execution_count":52,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1699112777796,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"rY2FEsCAOaLu","outputId":"9172e33e-2e01-419a-e594-ebb26d2e6e12"},"outputs":[{"data":{"text/plain":["torch.float32"]},"execution_count":52,"metadata":{},"output_type":"execute_result"}],"source":["tensor = torch.arange(10., 100., 10.)\n","tensor.dtype"]},{"cell_type":"code","execution_count":53,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1699112792436,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"Cac8gRYjOeab","outputId":"0621a3da-104c-4af0-b3b4-86ad72f8a999"},"outputs":[{"data":{"text/plain":["tensor([10., 20., 30., 40., 50., 60., 70., 80., 90.], dtype=torch.float16)"]},"execution_count":53,"metadata":{},"output_type":"execute_result"}],"source":["tensor_float16 = tensor.type(torch.float16)\n","tensor_float16"]},{"cell_type":"code","execution_count":54,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":272,"status":"ok","timestamp":1699113116827,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"8Yqovld2Oj6s","outputId":"8f26de3c-aae5-46ed-b674-fb96de62f59b"},"outputs":[{"data":{"text/plain":["tensor([10, 20, 30, 40, 50, 60, 70, 80, 90], dtype=torch.int8)"]},"execution_count":54,"metadata":{},"output_type":"execute_result"}],"source":["tensor_int8 = tensor.type(torch.int8)\n","tensor_int8"]},{"cell_type":"markdown","metadata":{"id":"44GxVabar-xe"},"source":["> **Remarque :** Différents types de données peuvent prêter à confusion au début. Mais pensez-y comme ceci : plus le nombre est bas (par exemple 32, 16, 8), moins un ordinateur stocke la valeur avec précision. Et avec une quantité de stockage inférieure, cela se traduit généralement par un calcul plus rapide et un modèle global plus petit. Les réseaux de neurones mobiles fonctionnent souvent avec des entiers de 8 bits, plus petits et plus rapides à exécuter, mais moins précis que leurs homologues float32. Pour en savoir plus à ce sujet, j'avais lu sur [la précision en informatique](https://en.wikipedia.org/wiki/Precision_(computer_science)).\n","\n","> **Exercice :** Jusqu'à présent, nous avons couvert pas mal de méthodes tensorielles, mais il y en a bien d'autres dans la [documentation `torch.Tensor`](https://pytorch.org/docs/stable/tensors.html) , je vous recommande de passer 10 minutes à faire défiler et à examiner ceux qui attirent votre attention. Cliquez dessus, puis écrivez-les vous-même en code pour voir ce qui se passe."]},{"cell_type":"markdown","metadata":{"id":"7CkCtAYmGsHY"},"source":["### Operations de : Reshaping, stacking, squeezing and unsqueezing\n","\n","Souvent, vous souhaiterez remodeler ou modifier les dimensions de vos tenseurs sans réellement modifier les valeurs qu'ils contiennent.\n","\n","Pour ce faire, certaines méthodes populaires sont :\n","\n","| Méthode | Description en une ligne |\n","| ----- | ----- |\n","| [`torch.reshape(input, shape)`](https://pytorch.org/docs/stable/generated/torch.reshape.html#torch.reshape) | Remodèle `input` en `shape` (si compatible), peut également utiliser `torch.Tensor.reshape()`. |\n","| [`Tensor.view(shape)`](https://pytorch.org/docs/stable/generated/torch.Tensor.view.html) | Renvoie une vue du tenseur d'origine sous une « forme » différente mais partage les mêmes données que le tenseur d'origine. |\n","| [`torch.stack(tensors, dim=0)`](https://pytorch.org/docs/1.9.1/generated/torch.stack.html) | Concatène une séquence de « tenseurs » le long d'une nouvelle dimension (« dim »), tous les « tenseurs » doivent être de la même taille. |\n","| [`torch.squeeze(input)`](https://pytorch.org/docs/stable/generated/torch.squeeze.html) | Presse « input » pour supprimer toutes les dimensions avec la valeur « 1 ». |\n","| [`torch.unsqueeze(input, dim)`](https://pytorch.org/docs/1.9.1/generated/torch.unsqueeze.html) | Renvoie « input » avec une valeur de dimension de « 1 » ajoutée à « dim ». |\n","| [`torch.permute(input, dims)`](https://pytorch.org/docs/stable/generated/torch.permute.html) | Renvoie une *vue* de « l'entrée » d'origine avec ses dimensions permutées (réorganisées) en « dims ». |\n","\n","Pourquoi faire tout cela ?\n","\n","Parce que les modèles d'apprentissage profond (réseaux de neurones) consistent tous à manipuler les tenseurs d'une manière ou d'une autre. Et à cause des règles de multiplication matricielle, si vous avez des différences de forme, vous rencontrerez des erreurs. Ces méthodes vous aident à vous assurer que les opérations sur les éléments de vos tenseurs s'effectue correctement.\n","\n","Essayons-les.\n","\n","Tout d’abord, nous allons créer un tenseur."]},{"cell_type":"code","execution_count":55,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":278,"status":"ok","timestamp":1699113922337,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"EYjRTLOzG4Ev","outputId":"7c7b4c5f-2b76-46fd-fe2d-825e9f42f6d4"},"outputs":[{"data":{"text/plain":["(tensor([1., 2., 3., 4., 5., 6., 7.]), torch.Size([7]))"]},"execution_count":55,"metadata":{},"output_type":"execute_result"}],"source":["import torch\n","x = torch.arange(1., 8.)\n","x, x.shape"]},{"cell_type":"markdown","metadata":{"id":"3_VarMO9CoT8"},"source":["Ajout d'une seconde dimension au tenseur `x` avec  `torch.reshape()`."]},{"cell_type":"code","execution_count":56,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":352,"status":"ok","timestamp":1699113925706,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"US4WjpQ3SG-8","outputId":"cbc1e4e5-f161-4378-dc22-b0e018c0dcd6"},"outputs":[{"data":{"text/plain":["(tensor([[1., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7]))"]},"execution_count":56,"metadata":{},"output_type":"execute_result"}],"source":["x_reshaped = x.reshape(1, 7)\n","x_reshaped, x_reshaped.shape"]},{"cell_type":"markdown","metadata":{"id":"tig5xm0jCxuU"},"source":["We can also change the view with `torch.view()`."]},{"cell_type":"code","execution_count":58,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":514,"status":"ok","timestamp":1699113994849,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"WDN2BNe5TGfB","outputId":"8ae6a96d-9323-4df9-fc33-c4b4a8dfdb50"},"outputs":[{"data":{"text/plain":["(tensor([[1., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7]))"]},"execution_count":58,"metadata":{},"output_type":"execute_result"}],"source":["z = x.view(1, 7)\n","z, z.shape"]},{"cell_type":"markdown","metadata":{"id":"m8joAaUEC2NX"},"source":["N'oubliez pas cependant que changer la vue d'un tenseur avec `torch.view()` ne crée en réalité qu'une nouvelle vue du *même* tenseur.\n","\n","Donc le fait de changer la vue change également le tenseur d'origine."]},{"cell_type":"code","execution_count":59,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":276,"status":"ok","timestamp":1699114437883,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"2DxURVvXTGfC","outputId":"96778ee7-539a-4c3a-95b8-fb031345f7d2"},"outputs":[{"data":{"text/plain":["(tensor([[5., 2., 3., 4., 5., 6., 7.]]), tensor([5., 2., 3., 4., 5., 6., 7.]))"]},"execution_count":59,"metadata":{},"output_type":"execute_result"}],"source":["z[:, 0] = 5\n","z, x"]},{"cell_type":"markdown","metadata":{"id":"YxnqDBlpDDJ_"},"source":["Si nous voulions empiler notre nouveau tenseur sur lui-même cinq fois, nous pourrions le faire avec `torch.stack()`."]},{"cell_type":"code","execution_count":64,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1699114517336,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"pX5Adf3ORiTK","outputId":"357b63d7-87ed-4a8a-db67-9313f4bf95ca"},"outputs":[{"data":{"text/plain":["tensor([[5., 2., 3., 4., 5., 6., 7.],\n","        [5., 2., 3., 4., 5., 6., 7.],\n","        [5., 2., 3., 4., 5., 6., 7.],\n","        [5., 2., 3., 4., 5., 6., 7.]])"]},"execution_count":64,"metadata":{},"output_type":"execute_result"}],"source":["x_stacked = torch.stack([x, x, x, x], dim=0) # try changing dim to dim=1 and see what happens\n","x_stacked"]},{"cell_type":"markdown","metadata":{"id":"ET56QzNHDuOI"},"source":["Que diriez-vous de supprimer toutes les dimensions singulière d'un tenseur ?\n","Pour ce faire, vous pouvez utiliser `torch.squeeze()` (la signification de squeeze est de *presser* ou *compresser* le tenseur pour n'avoir que des dimensions supérieures ayant un nombre d'éléments > 1)."]},{"cell_type":"code","execution_count":69,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":250,"status":"ok","timestamp":1699114765268,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"w2Y2HEoDRxJZ","outputId":"7bb91e2c-0827-4437-9cdb-58c0e02d176b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Previous tensor: tensor([[[5., 2., 3., 4., 5., 6., 7.]]])\n","Previous shape: torch.Size([1, 1, 7])\n","\n","New tensor: tensor([5., 2., 3., 4., 5., 6., 7.])\n","New shape: torch.Size([7])\n"]}],"source":["x_reshaped=x_reshaped.reshape(1, 1, 7)\n","print(f\"Previous tensor: {x_reshaped}\")\n","print(f\"Previous shape: {x_reshaped.shape}\")\n","\n","# Remove extra dimension from x_reshaped\n","x_squeezed = x_reshaped.squeeze()\n","print(f\"\\nNew tensor: {x_squeezed}\")\n","print(f\"New shape: {x_squeezed.shape}\")"]},{"cell_type":"markdown","metadata":{"id":"acjDLk8WD8NC"},"source":["Et pour faire l'inverse de `torch.squeeze()`, vous pouvez utiliser `torch.unsqueeze()` pour ajouter une valeur de dimension de 1 à un index spécifique."]},{"cell_type":"code","execution_count":70,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":247,"status":"ok","timestamp":1699114816671,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"CUC-DEEwSYv7","outputId":"7b01015b-d0f9-43b1-bfe9-0c635704d4c9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Previous tensor: tensor([5., 2., 3., 4., 5., 6., 7.])\n","Previous shape: torch.Size([7])\n","\n","New tensor: tensor([[5., 2., 3., 4., 5., 6., 7.]])\n","New shape: torch.Size([1, 7])\n"]}],"source":["print(f\"Previous tensor: {x_squeezed}\")\n","print(f\"Previous shape: {x_squeezed.shape}\")\n","\n","## Add an extra dimension with unsqueeze\n","x_unsqueezed = x_squeezed.unsqueeze(dim=0)\n","print(f\"\\nNew tensor: {x_unsqueezed}\")\n","print(f\"New shape: {x_unsqueezed.shape}\")"]},{"cell_type":"markdown","metadata":{"id":"R9DuJzXgFbM5"},"source":["\n","---\n","\n","Les données sont souvent conduites aux réseaux de neurones sous forme de lot (petit ensemble d'une dixaine/centaines d'éléments). Un lot est généralement de taille (32, forme d'un élément ). Les deux opérations précédentes sont bénéfiques par exemple pour créer un lot de données à partir des éléments ou bien lors de l'évaluation d'une seule instance de donnée par les réseaux de neurones en la convertissant en un lot de taille (1, forme de l'élément).\n","\n","Vous pouvez également réorganiser l'ordre des valeurs des axes avec `torch.permute(input, dims)`, où `input` est transformé en une *vue* avec de nouveaux `dims`."]},{"cell_type":"code","execution_count":71,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":259,"status":"ok","timestamp":1699115825361,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"fCRGCX8DTGfC","outputId":"b6d725eb-558a-477c-c4ce-f595409e55da"},"outputs":[{"name":"stdout","output_type":"stream","text":["Previous shape: torch.Size([224, 224, 3])\n","New shape: torch.Size([3, 224, 224])\n"]}],"source":["x_original = torch.rand(size=(224, 224, 3))\n","\n","x_permuted = x_original.permute(2, 0, 1) # permuter les axes dans l'ordre suivant: 0->1, 1->2, 2->0\n","\n","print(f\"Previous shape: {x_original.shape}\")\n","print(f\"New shape: {x_permuted.shape}\")"]},{"cell_type":"markdown","metadata":{"id":"06LKaFemGBoE"},"source":["> **Remarque** : Étant donné que la permutation renvoie une *vue* (partage les mêmes données que l'original), les valeurs du tenseur permuté seront les mêmes que le tenseur d'origine et si vous modifiez les valeurs dans la vue, ce sera le cas. modifier les valeurs de l'original."]},{"cell_type":"markdown","metadata":{"id":"nEPqVL7fTGfC"},"source":["## Operations d'Indexing (selection d'éléments de tenseurs)\n","\n","Parfois, vous souhaiterez sélectionner des données spécifiques à partir des tenseurs (par exemple, uniquement la première colonne ou la deuxième ligne).\n","\n","Pour ce faire, vous pouvez utiliser l'indexation.\n","\n","Si vous avez déjà indexé sur des listes Python ou des tableaux NumPy, l'indexation dans PyTorch avec des tenseurs est très similaire."]},{"cell_type":"code","execution_count":73,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":293,"status":"ok","timestamp":1699115983662,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"oSXzdxCQTGfD","outputId":"8dfbe20d-79e7-4e61-c1f5-8f5703686c50"},"outputs":[{"data":{"text/plain":["(tensor([[[1, 2, 3],\n","          [4, 5, 6],\n","          [7, 8, 9]]]),\n"," torch.Size([1, 3, 3]))"]},"execution_count":73,"metadata":{},"output_type":"execute_result"}],"source":["import torch\n","x = torch.arange(1, 10).reshape(1, 3, 3)\n","x, x.shape"]},{"cell_type":"markdown","metadata":{"id":"xQG5krnKG43B"},"source":["Indexing values goes outer dimension -> inner dimension (check out the square brackets)."]},{"cell_type":"code","execution_count":74,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1699115991905,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"zv_Z3IAzTGfD","outputId":"ca91c693-180c-4f64-ab52-c2073b3efc32"},"outputs":[{"name":"stdout","output_type":"stream","text":["First square bracket:\n","tensor([[1, 2, 3],\n","        [4, 5, 6],\n","        [7, 8, 9]])\n","Second square bracket: tensor([1, 2, 3])\n","Third square bracket: 1\n"]}],"source":["print(f\"First square bracket:\\n{x[0]}\")\n","print(f\"Second square bracket: {x[0][0]}\")\n","print(f\"Third square bracket: {x[0][0][0]}\")"]},{"cell_type":"code","execution_count":75,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1699116353603,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"gCT09pqeTGfD","outputId":"e835e031-88ff-4728-86d3-eba59d33164f"},"outputs":[{"data":{"text/plain":["tensor([[1, 2, 3]])"]},"execution_count":75,"metadata":{},"output_type":"execute_result"}],"source":["x[:, 0]"]},{"cell_type":"code","execution_count":76,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1699116371917,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"dwDx_gMsTGfD","outputId":"9045a23f-99a1-457c-9875-651cd88bcec3"},"outputs":[{"data":{"text/plain":["tensor([[2, 5, 8]])"]},"execution_count":76,"metadata":{},"output_type":"execute_result"}],"source":["x[:, :, 1]"]},{"cell_type":"code","execution_count":77,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1699116374943,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"xiw3_1E3TGfD","outputId":"f855fbc9-8e55-4208-d0e1-1782fb17e40d"},"outputs":[{"data":{"text/plain":["tensor([5])"]},"execution_count":77,"metadata":{},"output_type":"execute_result"}],"source":["x[:, 1, 1]"]},{"cell_type":"code","execution_count":78,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1699116384684,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"XFVEgrKhTGfD","outputId":"4359e61d-93d1-4fd0-bce4-728ea426912b"},"outputs":[{"data":{"text/plain":["tensor([1, 2, 3])"]},"execution_count":78,"metadata":{},"output_type":"execute_result"}],"source":["x[0, 0, :]"]},{"cell_type":"markdown","metadata":{"id":"h8ZaW0Bq7rCm"},"source":["## PyTorch & NumPy\n","\n","Étant donné que NumPy est une bibliothèque de calcul numérique Python populaire, PyTorch dispose de fonctionnalités permettant d'interagir correctement avec elle.\n","\n","Les deux méthodes principales que vous souhaiterez utiliser pour NumPy vers PyTorch (et vice-versa) sont :\n","* [`torch.from_numpy(ndarray)`](https://pytorch.org/docs/stable/generated/torch.from_numpy.html) - Tableau NumPy -> Tenseur PyTorch.\n","* [`torch.Tensor.numpy()`](https://pytorch.org/docs/stable/generated/torch.Tensor.numpy.html) - Tenseur PyTorch -> Tableau NumPy.\n","\n","Essayons-les."]},{"cell_type":"code","execution_count":79,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1699116459569,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"yDrDCnvY7rKS","outputId":"bc824a55-d362-4e97-808c-b39716c37409"},"outputs":[{"data":{"text/plain":["(array([1., 2., 3., 4., 5., 6., 7.]),\n"," tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"]},"execution_count":79,"metadata":{},"output_type":"execute_result"}],"source":["import torch\n","import numpy as np\n","array = np.arange(1.0, 8.0)\n","tensor = torch.from_numpy(array)\n","array, tensor"]},{"cell_type":"markdown","metadata":{"id":"16JG6cONLPnO"},"source":["> **Remarque :** Par défaut, les tableaux NumPy sont créés avec le type de données « float64 » et si vous le convertissez en tenseur PyTorch, il conservera le même type de données (comme ci-dessus).\n",">\n","> Cependant, de nombreux calculs PyTorch utilisent par défaut `float32`.\n",">\n","> Donc, si vous souhaitez convertir votre tableau NumPy (float64) -> Tenseur PyTorch (float64) -> Tenseur PyTorch (float32), vous pouvez utiliser `tensor = torch.from_numpy(array).type(torch.float32)`.\n","\n","Parce que nous avons réaffecté le `tensor` ci-dessus, si vous modifiez le tenseur, le tableau reste le même."]},{"cell_type":"code","execution_count":81,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1699116538469,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"ovwl7VCREv8L","outputId":"42389f80-7163-412a-aa61-93e053dda0e1"},"outputs":[{"data":{"text/plain":["(array([3., 4., 5., 6., 7., 8., 9.]),\n"," tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"]},"execution_count":81,"metadata":{},"output_type":"execute_result"}],"source":["array = array + 1\n","array, tensor"]},{"cell_type":"markdown","metadata":{"id":"geVvu1p0MTWc"},"source":["l'utilisation de `tensor.numpy()` est similaire :"]},{"cell_type":"code","execution_count":82,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1699116617239,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"xw_7ZyVaTKxQ","outputId":"2d8cacd4-eb2c-4b6e-80f6-2d3d8fdd37cc"},"outputs":[{"data":{"text/plain":["(tensor([1., 1., 1., 1., 1., 1., 1.]),\n"," array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"]},"execution_count":82,"metadata":{},"output_type":"execute_result"}],"source":["tensor = torch.ones(7)\n","numpy_tensor = tensor.numpy()\n","tensor, numpy_tensor"]},{"cell_type":"markdown","metadata":{"id":"Dt8yEV1jMfi2"},"source":["Et la même règle s'applique que ci-dessus, si vous modifiez le `tensor` d'origine, le nouveau `numpy_tensor` reste le même."]},{"cell_type":"code","execution_count":83,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1699116656497,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"mMp6ZSkET4_Y","outputId":"f7e95d4b-4132-425c-817b-b8f51769136e"},"outputs":[{"data":{"text/plain":["(tensor([2., 2., 2., 2., 2., 2., 2.]),\n"," array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"]},"execution_count":83,"metadata":{},"output_type":"execute_result"}],"source":["tensor = tensor + 1\n","tensor, numpy_tensor"]},{"cell_type":"markdown","metadata":{"id":"7gU3ubCrUkI-"},"source":["## Reproductibilité (essayer d'enlever le hasard de l'aléatoire)\n","\n","Au fur et à mesure que vous en apprendrez davantage sur les réseaux de neurones et l’apprentissage automatique, vous commencerez à découvrir à quel point le hasard joue un rôle.\n","\n","Eh bien, c’est du pseudo-aléatoire. Parce qu'après tout, tels qu'ils sont conçus, un ordinateur est fondamentalement déterministe (chaque étape est prévisible), donc le caractère aléatoire qu'ils créent est un hasard simulé.\n","\n","> Quel est alors le rapport avec les réseaux de neurones et l’apprentissage profond ?\n",">\n","> Nous avons discuté des réseaux de neurones en commençant par des nombres aléatoires pour representer les structures dans les données (ces nombres sont de mauvaises representations) en essaye donc à l'aide des algorithmes d'optimisations d'améliorer ces nombres aléatoires initiale en utilisant des opérations tensorielles pour mieux décrire les patterns des données.\n","\n","En bref:\n","\n","``commencez par des nombres aléatoires -> opérations tensorielles -> essayez de faire mieux``\n","\n","Bien que le hasard soit agréable et puissant, on aimerait parfois qu'il y ait un peu moins de hasard.\n","\n","Pourquoi?\n","\n","Vous pouvez ainsi réaliser des expériences reproductibles.\n","\n","Par exemple, vous créez un algorithme capable d’atteindre des performances X.\n","\n","Et puis votre ami essaie pour vérifier la justesse des résultats.\n","\n","Comment pourait-ils le faire d'une manière pareille ?\n","\n","C'est là qu'intervient la **reproductibilité**.\n","\n","En d’autres termes, pouvez-vous obtenir des résultats identiques (ou très similaires) sur votre ordinateur en exécutant le même code que le mien ?\n","\n","Voyons un bref exemple de reproductibilité dans PyTorch.\n","\n","Nous allons commencer par créer deux tenseurs aléatoires, puisqu'ils sont aléatoires, on s'attendrait à ce qu'ils soient différents, n'est-ce pas ?"]},{"cell_type":"code","execution_count":84,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":360,"status":"ok","timestamp":1699117035784,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"eSwxnwEbTGfF","outputId":"a9877704-1479-414a-d13e-e4292c41b468"},"outputs":[{"name":"stdout","output_type":"stream","text":["Tensor A:\n","tensor([[0.8016, 0.3649, 0.6286, 0.9663],\n","        [0.7687, 0.4566, 0.5745, 0.9200],\n","        [0.3230, 0.8613, 0.0919, 0.3102]])\n","\n","Tensor B:\n","tensor([[0.9536, 0.6002, 0.0351, 0.6826],\n","        [0.3743, 0.5220, 0.1336, 0.9666],\n","        [0.9754, 0.8474, 0.8988, 0.1105]])\n","\n","Does Tensor A equal Tensor B? (anywhere)\n"]},{"data":{"text/plain":["tensor([[False, False, False, False],\n","        [False, False, False, False],\n","        [False, False, False, False]])"]},"execution_count":84,"metadata":{},"output_type":"execute_result"}],"source":["import torch\n","\n","random_tensor_A = torch.rand(3, 4)\n","random_tensor_B = torch.rand(3, 4)\n","\n","print(f\"Tensor A:\\n{random_tensor_A}\\n\")\n","print(f\"Tensor B:\\n{random_tensor_B}\\n\")\n","print(f\"Does Tensor A equal Tensor B? (anywhere)\")\n","random_tensor_A == random_tensor_B"]},{"cell_type":"markdown","metadata":{"id":"nPU6mDKJnr8M"},"source":["Comme vous vous en doutez peut-être, les tenseurs donnent des valeurs différentes.\n","\n","Mais que se passe-t-il si vous souhaitez créer deux tenseurs aléatoires avec les *mêmes* valeurs.\n","\n","Comme dans, les tenseurs contiendraient toujours des valeurs aléatoires mais ils auraient la même saveur.\n","\n","C'est là qu'intervient [`torch.manual_seed(seed)`](https://pytorch.org/docs/stable/generated/torch.manual_seed.html), où `seed` est un entier fixé\n","par l'utilisateur.\n","\n","Essayons-le en créant d'autres tenseurs aléatoires."]},{"cell_type":"code","execution_count":85,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1699117165450,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"sB6d1GfYTGfF","outputId":"6377403d-5164-4a0a-e4ed-60f0accdd815"},"outputs":[{"name":"stdout","output_type":"stream","text":["Tensor C:\n","tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n","        [0.3904, 0.6009, 0.2566, 0.7936],\n","        [0.9408, 0.1332, 0.9346, 0.5936]])\n","\n","Tensor D:\n","tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n","        [0.3904, 0.6009, 0.2566, 0.7936],\n","        [0.9408, 0.1332, 0.9346, 0.5936]])\n","\n","Does Tensor C equal Tensor D? (anywhere)\n"]},{"data":{"text/plain":["tensor([[True, True, True, True],\n","        [True, True, True, True],\n","        [True, True, True, True]])"]},"execution_count":85,"metadata":{},"output_type":"execute_result"}],"source":["import torch\n","import random\n","\n","\n","RANDOM_SEED=42\n","torch.manual_seed(seed=RANDOM_SEED)\n","random_tensor_C = torch.rand(3, 4)\n","\n","# reinitialisation du seed avec la meme instuction\n","torch.random.manual_seed(seed=RANDOM_SEED)\n","random_tensor_D = torch.rand(3, 4)\n","\n","print(f\"Tensor C:\\n{random_tensor_C}\\n\")\n","print(f\"Tensor D:\\n{random_tensor_D}\\n\")\n","print(f\"Does Tensor C equal Tensor D? (anywhere)\")\n","random_tensor_C == random_tensor_D"]},{"cell_type":"markdown","metadata":{"id":"uct53Xr5QRC_"},"source":["> **Ressource :** Ce que nous venons de couvrir ne fait qu'effleurer la surface de la reproductibilité dans PyTorch. Pour en savoir plus, sur la reproductibilité en général et les `seed` aléatoires, consulter :\n","> * [La documentation de reproductibilité de PyTorch](https://pytorch.org/docs/stable/notes/randomness.html) (un bon exercice serait de le lire pendant 10 minutes et même si vous ne le comprenez pas maintenant, il est important d'en être conscient).\n","> * [La page sur les seed aléatoires de Wikipédia](https://en.wikipedia.org/wiki/Random_seed) (cela donnera un bon aperçu des seed générateurs aléatoires et du caractère pseudo-aléatoire en général)."]},{"cell_type":"markdown","metadata":{"id":"hxIIM7t27rQ-"},"source":["## Utilisation des tenseurs sur GPUs\n","\n","Les algorithmes d’apprentissage profond nécessitent de nombreuses opérations numériques.\n","\n","Et par défaut ces opérations sont souvent effectuées sur un CPU (unité centrale de traitement).\n","\n","Cependant, il existe un autre élément matériel courant appelé GPU (unité de traitement graphique), qui est souvent beaucoup plus rapide pour effectuer les types spécifiques d'opérations dont les réseaux neuronaux ont besoin (multiplications matricielles) que les processeurs.\n","\n","Votre ordinateur en a peut-être un / sin non vous pouvez utiliser un gratuitement sur google colab.\n","\n","Vous devriez envisager de l'utiliser chaque fois que vous le pouvez pour entraîner des réseaux de neurones, car il est probable que cela accélérera considérablement le temps d'entraînement.\n","\n","Il existe plusieurs façons d’accéder d’abord à un GPU et ensuite de demander à PyTorch d’utiliser le GPU."]},{"cell_type":"markdown","metadata":{"id":"0UiR6QpoYQH_"},"source":["### 1. Obtenir un GPU\n","\n","Il existe plusieurs façons d’obtenir un GPU.\n","\n","| **Méthode** | **Difficulté à configurer** | **Avantages** | **Inconvénients** | **Comment configurer** |\n","| ----- | ----- | ----- | ----- | ----- |\n","| GoogleColab | Facile | Utilisation gratuite, presque aucune configuration requise, peut partager le travail avec d'autres aussi facilement qu'un lien | N'enregistre pas vos sorties de données, calcul limité, soumis à des délais d'attente | [Suivez le guide Google Colab](https://colab.research.google.com/notebooks/gpu.ipynb) |\n","| Utilisez votre propre | Moyen | Exécutez tout localement sur votre propre machine | Les GPU ne sont pas gratuits et nécessitent un coût initial | Suivez les [Directives d'installation de PyTorch](https://pytorch.org/get-started/locally/) |\n","| Service Cloud (AWS, GCP, Azure) | Moyen-dur | Petit coût initial, accès à un calcul presque infini | Peut coûter cher s'il fonctionne en continu, la configuration prend un certain temps | Suivez les [Directives d'installation de PyTorch](https://pytorch.org/get-started/cloud-partners/) |\n","\n","Il existe davantage d’options pour utiliser les GPU, mais les trois ci-dessus suffiront pour le moment.\n","\n","Pour des expériences à petite échelle, une combinaison de Google Colab et de votre propre ordinateur sont largement suffisent.\n","\n","> **Ressource :** Si vous souhaitez acheter votre propre GPU mais que vous ne savez pas quoi acheter, [Guide Pour ACHAT de GPU](https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/).\n","\n","Pour vérifier si vous avez accès à un GPU Nvidia, vous pouvez exécuter `!nvidia-smi` où le `!` (également appelé bang) signifie « exécuter ceci sur la ligne de commande »."]},{"cell_type":"code","execution_count":88,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":294,"status":"ok","timestamp":1699117842817,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"vEMcO-9zYc-w","outputId":"f9371532-89ef-45dc-e365-b2859d290dad"},"outputs":[{"name":"stdout","output_type":"stream","text":["/bin/bash: line 1: nvidia-smi: command not found\n"]}],"source":["!nvidia-smi"]},{"cell_type":"markdown","metadata":{"id":"UvibZ6e0YcDk"},"source":["\n","\n","### 2. PyTorch et GPU\n","\n","Une fois que vous disposez d'un GPU prêt à accéder, l'étape suivante consiste à utiliser PyTorch pour stocker des données (tenseurs) et calculer sur les données (effectuer des opérations sur des tenseurs).\n","\n","Pour ce faire, vous pouvez utiliser le package [`torch.cuda`](https://pytorch.org/docs/stable/cuda.html).\n","\n","Vous pouvez tester si PyTorch a accès à un GPU en utilisant [`torch.cuda.is_available()`](https://pytorch.org/docs/stable/generated/torch.cuda.is_available.html#torch.cuda.is_available ).\n","\n","En utilisant Google Colab. Changer le runtime de votre environement en selectionant un GPU adequat voire T4 GPU. Documenter vous sur Google Colab afin de preparer votre premier notebook sur Colab.\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":308,"status":"ok","timestamp":1699118219811,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"OweDLgwjEvZ2","outputId":"e5308fb5-8a4d-44cb-c093-699a925efdef"},"outputs":[{"data":{"text/plain":["True"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["# Check for GPU\n","import torch\n","torch.cuda.is_available()"]},{"cell_type":"markdown","metadata":{"id":"jedZcx2PZFpL"},"source":["Si ce qui précède renvoie « Vrai », PyTorch peut voir et utiliser le GPU, s'il renvoie « False », il ne peut pas voir le GPU et dans ce cas, vous devrez revenir sur les étapes d'installation.\n","\n","Maintenant, disons que vous vouliez configurer votre code pour qu'il s'exécute sur le CPU *ou* le GPU s'il était disponible.\n","\n","De cette façon, si vous ou quelqu'un décidez d'exécuter votre code, il fonctionnera quel que soit l'appareil qu'il utilise.\n","\n","Créons une variable « device » pour stocker le type de périphérique disponible."]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"elapsed":397,"status":"ok","timestamp":1699118285803,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"j92HBCKB7rYa","outputId":"dc8aafa3-8054-49c7-9172-374b1ea7afa2"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'cuda'"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# Set device type\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","device"]},{"cell_type":"markdown","metadata":{"id":"FjFyPP2WaCch"},"source":["Si le résultat ci-dessus `\"cuda\"`, cela signifie que nous pouvons configurer tout notre code PyTorch pour utiliser le périphérique CUDA disponible (un GPU) et s'il génère `\"cpu\"`, notre code PyTorch restera fidèle au CPU.\n","\n","> **Remarque :** Dans PyTorch, il est recommandé d'écrire du [**code indépendant du périphérique**](https://pytorch.org/docs/master/notes/cuda.html#device-agnostic-code). Cela signifie du code qui s'exécutera sur CPU (toujours disponible) ou GPU (si disponible).\n","\n","Si vous souhaitez effectuer un calcul plus rapide, vous pouvez utiliser un GPU, mais si vous souhaitez effectuer un calcul *beaucoup* plus rapide, vous pouvez utiliser plusieurs GPU.\n","\n","Vous pouvez compter le nombre de GPU auxquels PyTorch a accès en utilisant [`torch.cuda.device_count()`](https://pytorch.org/docs/stable/generated/torch.cuda.device_count.html#torch.cuda. nombre_appareil)."]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1699118344134,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"MArsn0DFTGfG","outputId":"ec5c8915-74c5-4d5c-da84-5de4917417d5"},"outputs":[{"data":{"text/plain":["1"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["torch.cuda.device_count()"]},{"cell_type":"markdown","metadata":{"id":"xVNf1hiqa-gO"},"source":["Connaître le nombre de GPU auxquels PyTorch a accès est utile si vous souhaitez exécuter un processus spécifique sur un GPU et un autre processus sur un autre (PyTorch dispose également de fonctionnalités pour vous permettre d'exécuter un processus sur *tous* les GPU)."]},{"cell_type":"markdown","metadata":{"id":"XqQLcuj68OA-"},"source":["### 3. Mettre des tenseurs (et des modèles) sur le GPU\n","\n","Vous pouvez placer des tenseurs (et des modèles de neurones) sur un appareil spécifique en appelant [`.to(device)`](https://pytorch.org/docs/stable/generated/torch.Tensor.to. html) sur eux. Où « device » est le périphérique cible auquel vous souhaitez que le tenseur (ou le modèle) aille.\n","\n","Pourquoi faire ceci?\n","\n","Les GPU offrent un calcul numérique beaucoup plus rapide que les CPU et si un GPU n'est pas disponible, en raison de notre **code indépendant du périphérique** (voir ci-dessus), il fonctionnera sur le CPU.\n","\n","> **Remarque :** Mettre un tenseur sur GPU à l'aide de `to(device)` (par exemple `some_tensor.to(device)`) renvoie une copie de ce tenseur, par exemple le même tenseur sera sur CPU et GPU. Pour écraser les tenseurs, réaffectez-les :\n",">\n","> `some_tensor = some_tensor.to(device)`\n","\n","Essayons de créer un tenseur et de le mettre sur le GPU (s'il est disponible)."]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5861,"status":"ok","timestamp":1699118447183,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"FhI3srFXEHfP","outputId":"93aa4ed7-5114-4ac2-d777-ee385477b2cf"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([1, 2, 3]) cpu\n"]},{"data":{"text/plain":["tensor([1, 2, 3], device='cuda:0')"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["tensor = torch.tensor([1, 2, 3])\n","\n","# tensor sur CPU par defaut\n","print(tensor, tensor.device)\n","\n","# deplacer vers le GPU\n","tensor_on_gpu = tensor.to(device)\n","tensor_on_gpu"]},{"cell_type":"markdown","metadata":{"id":"DxXeRKO0TGfG"},"source":["Si vous disposez d'un GPU, le resultat :\n","```\n","tensor([1, 2, 3]) cpu\n","tensor([1, 2, 3], device='cuda:0')\n","```\n","\n","Notez que le deuxième tenseur a `device='cuda:0'`, cela signifie qu'il est stocké sur le 0ème GPU disponible (les GPU sont indexés à 0, si deux GPU étaient disponibles, ils seraient `'cuda:0'` et `' cuda:1'` respectivement, jusqu'à ``cuda:n'`).\n","\n"]},{"cell_type":"markdown","metadata":{"id":"4puyUX4Bci5D"},"source":["### 4. Retourner les tenseurs vers le CPU\n","\n","Et si nous voulions ramener le tenseur vers le CPU ?\n","\n","Par exemple, vous souhaiterez faire cela si vous souhaitez interagir avec vos tenseurs avec NumPy (NumPy n'exploite pas le GPU).\n","\n","Essayons d'utiliser la méthode [`torch.Tensor.numpy()`](https://pytorch.org/docs/stable/generated/torch.Tensor.numpy.html) sur notre `tensor_on_gpu`."]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":199},"executionInfo":{"elapsed":382,"status":"error","timestamp":1699118551143,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"3ChSLJgPTGfG","outputId":"3210d126-68d6-4cab-85c4-5b0ced93b096"},"outputs":[{"ename":"TypeError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-53175578f49e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# If tensor is on GPU, can't transform it to NumPy (this will error)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtensor_on_gpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."]}],"source":["# si le tensor est sur GPU, on ne peut par le transformer en NumPy (Numpy = CPU uniquement)\n","tensor_on_gpu.numpy()"]},{"cell_type":"markdown","metadata":{"id":"LhymtkRDTGfG"},"source":["Au lieu de cela, pour remettre un tenseur au CPU et utilisable avec NumPy, nous pouvons utiliser [`Tensor.cpu()`](https://pytorch.org/docs/stable/generated/torch.Tensor.cpu.html).\n","\n","Cela copie le tenseur dans la mémoire du processeur afin qu'il soit utilisable avec les processeurs."]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":309,"status":"ok","timestamp":1699118611280,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"gN15s-NdTGfG","outputId":"8640a24c-3070-49a6-cb3d-7fad59b36735"},"outputs":[{"data":{"text/plain":["array([1, 2, 3])"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n","tensor_back_on_cpu"]},{"cell_type":"markdown","metadata":{"id":"qyzNH5lrTGfH"},"source":["Ce qui précède renvoie une copie du tenseur GPU dans la mémoire CPU afin que le tenseur d'origine soit toujours sur le GPU."]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":313,"status":"ok","timestamp":1699118634987,"user":{"displayName":"Hamza KHALFI","userId":"11532833024180314482"},"user_tz":-60},"id":"S5u83PCRTGfH","outputId":"de2e1b10-be99-498a-dff5-e3e8b66401d3"},"outputs":[{"data":{"text/plain":["tensor([1, 2, 3], device='cuda:0')"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["tensor_on_gpu"]},{"cell_type":"markdown","metadata":{"id":"xlmBpnuPTGfH"},"source":["## Exercices\n","\n","Tous les exercices sont axés sur la pratique du code ci-dessus.\n","\n","Vous devriez pouvoir les compléter en faisant référence à chaque section ou en suivant la ou les ressources liées.\n","\n","***Ressources :***\n","\n","1. Lecture de la documentation – Une grande partie de l'apprentissage en profondeur (et de l'apprentissage du code en général) consiste à se familiariser avec la documentation d'un certain framework que vous utilisez. Nous utiliserons beaucoup la documentation PyTorch tout au long du reste de ce cours.  Voir la documentation sur [`torch.Tensor`](https://pytorch.org/docs/stable/tensors.html#torch-tensor) et pour [`torch.cuda`](https://pytorch.org/ docs/master/notes/cuda.html#cuda-semantics).\n","2. Créez un tenseur aléatoire de forme « (7, 7) ».\n","3. Effectuez une multiplication matricielle sur le tenseur de 2 avec un autre tenseur aléatoire de forme `(1, 7)` (indice : vous devrez peut-être transposer le deuxième tenseur).\n","4. Réglez la valeur aléatoire sur « 0 » et refaites les exercices 2 et 3.\n","5. En parlant de seed aléatoires, nous avons vu comment les définir avec `torch.manual_seed()` mais existe-t-il un équivalent GPU ? (indice : vous devrez consulter la documentation de « torch.cuda » pour celui-ci). Si tel est le cas, définissez la valeur de départ aléatoire du GPU sur « 1234 ».\n","6. Créez deux tenseurs aléatoires de forme `(2, 3)` et envoyez-les tous les deux au GPU (vous aurez besoin d'accéder à un GPU pour cela). Définissez `torch.manual_seed(1234)` lors de la création des tenseurs (il n'est pas nécessaire que ce soit le seed aléatoire du GPU).\n","7. Effectuez une multiplication matricielle sur les tenseurs que vous avez créés en 6 (encore une fois, vous devrez peut-être ajuster les formes de l'un des tenseurs).\n","8. Trouvez les valeurs maximales et minimales de la sortie de 7.\n","9. Trouvez les valeurs d'index maximales et minimales de la sortie de 7.\n","10. Créez un tenseur aléatoire de forme « (1, 1, 1, 10) », puis créez un nouveau tenseur avec toutes les dimensions « 1 » supprimées pour laisser un tenseur de forme « (10) ». Réglez le seed sur « 7 » lorsque vous la créez et imprimez le premier tenseur et sa forme ainsi que le deuxième tenseur et sa forme."]},{"cell_type":"markdown","metadata":{"id":"I93jJp30A8lM"},"source":["## BoNuS\n","\n","* Prenez une heure de votre temps pour explorer les tutoriels [PyTorch basics tutorial](https://pytorch.org/tutorials/beginner/basics/intro.html) (Consulter aussi la partie [Quickstart](https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html) and [Tensors](https://pytorch.org/tutorials/beginner/basics/tensorqs_tutorial.html)).\n","* La section : [Introduction to PyTorch - YouTube Series](https://pytorch.org/tutorials/beginner/introyt.html) contient une revue de tous les notions basiques de Pytorch qu'on va voir dans ce module."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C9L8UzTdZUSr"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1aKzCu9Zn50-wPz7y_bTACDcNBOMsMy2U","timestamp":1699119318031}]},"interpreter":{"hash":"3fbe1355223f7b2ffc113ba3ade6a2b520cadace5d5ec3e828c83ce02eb221bf"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":0}
